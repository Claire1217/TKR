{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tkr_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(num_epochs):\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    model = models.resnet34(pretrained=False)\n",
    "            # Download torchvision pretrained model from: https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
    "    model.load_state_dict(torch.load('resnet34-333f7ec4.pth'))\n",
    "    model.fc = nn.Linear(model_ft.fc.in_features, 1, bias=True)\n",
    "    model.to(device)\n",
    "\n",
    "    # Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
    "    \n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    best_accuracy = 0.0\n",
    "    train_loader = TKRDataset('/afm01/Q1/Q1126/OAI_UQ_processed/AKOA_TKR_Data', 0)\n",
    "    \n",
    "\n",
    "    # Define your execution device\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            # get the inputs\n",
    "            images = np.stack((images,)*3, axis=0)\n",
    "            images = np.reshape(images, [1,3,256,256])\n",
    "            images = torch.tensor(images, dtype=float).to(device, dtype=float)\n",
    "            labels = torch.tensor(labels, dtype=float).to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # predict classes using images from the training set\n",
    "            outputs = model(images.float())\n",
    "            pred = torch.sigmoid(outputs)[0][0]\n",
    "            \n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_fn(pred, labels.float())\n",
    "            print(pred.detach().numpy())\n",
    "            print(labels.numpy())\n",
    "            print(loss.detach().numpy())\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            if i % 20 == 0:    \n",
    "                # print every 1000 (twice per epoch) \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                        (epoch + 1, i + 1, running_loss / 20))\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Param = {\n",
    "    'LR': 0.001,\n",
    "    'WC': 0.0001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cpu_test(num_epochs, model_type):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    if model_type == 'resnet34':\n",
    "        model = models.resnet34(pretrained=False)\n",
    "                # Download torchvision pretrained model from: https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
    "        model.load_state_dict(torch.load('resnet34-333f7ec4.pth'))\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1, bias=True)\n",
    "        model.to(device)\n",
    "    elif model_type == 'densenet':\n",
    "        model = models.densenet201(pretrained=True)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, 1, bias=True)\n",
    "    # Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
    "    elif model_type == 'cnn':\n",
    "        model = channel1().float()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=Param['LR'], weight_decay=Param['WC'])\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    print(os.getcwd())\n",
    "    train_loader = TKRDataset('R:\\OAIKNEE-Q1126\\OAI_UQ_processed\\AKOA_TKR_Data', 1)\n",
    "    \n",
    "\n",
    "    # Define your execution device\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            \n",
    "            # get the inputs\n",
    "\n",
    "\n",
    "            if model_type == 'resnet34' or model_type == 'densenet':\n",
    "                images = np.stack((images,)*3, axis=1)\n",
    "                images = torch.tensor(images, dtype=float).to(device, dtype=float)\n",
    "                labels = torch.tensor(labels, dtype=float).to(device)\n",
    "                optimizer.zero_grad()\n",
    "            # predict classes using images from the training set\n",
    "                outputs = model(images.reshape(4,3,256,256).float())\n",
    "                pred = torch.sigmoid(outputs)\n",
    "            else:\n",
    "            # zero the parameter gradients\n",
    "                images = torch.tensor(images, dtype=float).to(device, dtype=float)\n",
    "                labels = torch.tensor(labels, dtype=float).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                # predict classes using images from the training set\n",
    "                outputs = model(images.reshape(4,1,256,256).float())\n",
    "                \n",
    "                pred = torch.sigmoid(outputs)\n",
    "                print(labels)\n",
    "                print(pred)\n",
    "                \n",
    "\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_fn(pred[:,0], labels.float())\n",
    "            print(loss)\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            print('running')\n",
    "            print(running_loss)\n",
    "             # extract the loss value\n",
    "            if i % 20 == 0:     \n",
    "                # print every 1000 (twice per epoch) \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 20))\n",
    "                # zero the loss\n",
    "                if running_loss / 20 < 0.2:\n",
    "                    los = running_loss /20\n",
    "                    if Param['PL'] == 1:\n",
    "                        torch.save(model.state_dict(), f'weights/{model_type}_coronal_weights_iter{i}_loss{los}.pth')\n",
    "                    else:\n",
    "                        torch.save(model.state_dict(), f'weights/{model_type}_saggital_weights_iter{i}_loss{los}.pth')\n",
    "                \n",
    "                    \n",
    "            running_loss = 0.0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cpu device\n",
      "c:\\Users\\s4469251\\Documents\\codes\\AKOA_TKR\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.5331],\n",
      "        [0.4784],\n",
      "        [0.5479],\n",
      "        [0.5881]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6247, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6247403621673584\n",
      "[1,     1] loss: 0.031\n",
      "tensor([1., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.4906],\n",
      "        [0.5500],\n",
      "        [0.5980],\n",
      "        [0.5988]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6836, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.683563232421875\n",
      "tensor([1., 0., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.5717],\n",
      "        [0.5770],\n",
      "        [0.4972],\n",
      "        [0.6204]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6461, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6461183428764343\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.6099],\n",
      "        [0.6548],\n",
      "        [0.4208],\n",
      "        [0.6073]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5705, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.570531964302063\n",
      "tensor([0., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.5466],\n",
      "        [0.5835],\n",
      "        [0.5634],\n",
      "        [0.6618]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7469, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.7468916177749634\n",
      "tensor([0., 1., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.5650],\n",
      "        [0.6383],\n",
      "        [0.5735],\n",
      "        [0.5942]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7588, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.7588430643081665\n",
      "tensor([0., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.5840],\n",
      "        [0.6169],\n",
      "        [0.6590],\n",
      "        [0.5410]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7626, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.7625553607940674\n",
      "tensor([0., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.6693],\n",
      "        [0.6195],\n",
      "        [0.5464],\n",
      "        [0.5662]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7562, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.756237268447876\n",
      "tensor([0., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.5718],\n",
      "        [0.4900],\n",
      "        [0.6500],\n",
      "        [0.6783]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7816, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.7816379070281982\n",
      "tensor([0., 0., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.5787],\n",
      "        [0.5857],\n",
      "        [0.6174],\n",
      "        [0.6065]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8016392588615417\n",
      "tensor([1., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.5787],\n",
      "        [0.6963],\n",
      "        [0.5576],\n",
      "        [0.5652]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5738, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5737825632095337\n",
      "tensor([1., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.5800],\n",
      "        [0.6840],\n",
      "        [0.5942],\n",
      "        [0.5478]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8481, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8481073975563049\n",
      "tensor([0., 0., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.6480],\n",
      "        [0.6655],\n",
      "        [0.5349],\n",
      "        [0.5447]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8879, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8879498839378357\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.5593],\n",
      "        [0.7210],\n",
      "        [0.5449],\n",
      "        [0.5340]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5357, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5356605648994446\n",
      "tensor([0., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.6881],\n",
      "        [0.5716],\n",
      "        [0.6416],\n",
      "        [0.4468]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8890, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8889665007591248\n",
      "tensor([0., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.5356],\n",
      "        [0.6286],\n",
      "        [0.5662],\n",
      "        [0.5992]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6447, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6446774005889893\n",
      "tensor([1., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.5277],\n",
      "        [0.7300],\n",
      "        [0.4268],\n",
      "        [0.6315]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7009, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.7009392380714417\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.5987],\n",
      "        [0.6220],\n",
      "        [0.5847],\n",
      "        [0.5093]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5497, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5497393012046814\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.6422],\n",
      "        [0.5632],\n",
      "        [0.5365],\n",
      "        [0.5915]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5411669611930847\n",
      "tensor([0., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.4786],\n",
      "        [0.6909],\n",
      "        [0.5199],\n",
      "        [0.6427]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.549199104309082\n",
      "tensor([1., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.6308],\n",
      "        [0.4931],\n",
      "        [0.4616],\n",
      "        [0.7479]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5193, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5193382501602173\n",
      "[1,    21] loss: 0.026\n",
      "tensor([1., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.6508],\n",
      "        [0.5976],\n",
      "        [0.5491],\n",
      "        [0.5578]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5899, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5899444818496704\n",
      "tensor([1., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.7516],\n",
      "        [0.4979],\n",
      "        [0.5892],\n",
      "        [0.5097]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6442, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6442365646362305\n",
      "tensor([1., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.5665],\n",
      "        [0.6716],\n",
      "        [0.4614],\n",
      "        [0.6734]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8549, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8549067378044128\n",
      "tensor([1., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.7712],\n",
      "        [0.5736],\n",
      "        [0.5431],\n",
      "        [0.4524]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5071, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5071137547492981\n",
      "tensor([0., 1., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.7120],\n",
      "        [0.5848],\n",
      "        [0.5736],\n",
      "        [0.5187]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8412, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8412131667137146\n",
      "tensor([1., 0., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.7365],\n",
      "        [0.4819],\n",
      "        [0.6422],\n",
      "        [0.5156]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5172, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5171806812286377\n",
      "tensor([1., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.7529],\n",
      "        [0.6266],\n",
      "        [0.5874],\n",
      "        [0.4131]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.630140483379364\n",
      "tensor([0., 0., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.3819],\n",
      "        [0.4692],\n",
      "        [0.8524],\n",
      "        [0.6177]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.4390, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.4389748275279999\n",
      "tensor([1., 0., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.5350],\n",
      "        [0.5122],\n",
      "        [0.6774],\n",
      "        [0.6287]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7347, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.7346760034561157\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.5547],\n",
      "        [0.5169],\n",
      "        [0.7632],\n",
      "        [0.4949]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.9150, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.9150230884552002\n",
      "tensor([0., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.5879],\n",
      "        [0.4510],\n",
      "        [0.5306],\n",
      "        [0.7556]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6492, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6492181420326233\n",
      "tensor([1., 0., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.6744],\n",
      "        [0.5620],\n",
      "        [0.4132],\n",
      "        [0.6833]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8132, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.813223123550415\n",
      "tensor([1., 1., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.6393],\n",
      "        [0.5299],\n",
      "        [0.5207],\n",
      "        [0.6403]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7101, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.7100629806518555\n",
      "tensor([0., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.4228],\n",
      "        [0.6604],\n",
      "        [0.5738],\n",
      "        [0.6680]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5552, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5551961064338684\n",
      "tensor([1., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.7256],\n",
      "        [0.4344],\n",
      "        [0.5552],\n",
      "        [0.5761]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6398, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6397513747215271\n",
      "tensor([0., 1., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.4395],\n",
      "        [0.7420],\n",
      "        [0.6496],\n",
      "        [0.4655]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6381, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6381061673164368\n",
      "tensor([0., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.3886],\n",
      "        [0.6754],\n",
      "        [0.6138],\n",
      "        [0.6193]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.4629, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.4628945589065552\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.5752],\n",
      "        [0.4996],\n",
      "        [0.7307],\n",
      "        [0.4403]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8602, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8602094650268555\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.5213],\n",
      "        [0.4864],\n",
      "        [0.5837],\n",
      "        [0.6588]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8387, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8386533260345459\n",
      "tensor([0., 1., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.4082],\n",
      "        [0.5717],\n",
      "        [0.6137],\n",
      "        [0.6088]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7433, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.7433488965034485\n",
      "[1,    41] loss: 0.037\n",
      "tensor([0., 0., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.2897],\n",
      "        [0.5261],\n",
      "        [0.5366],\n",
      "        [0.7693]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.530110776424408\n",
      "tensor([0., 0., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.6175],\n",
      "        [0.4343],\n",
      "        [0.4366],\n",
      "        [0.6308]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6414, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.641361653804779\n",
      "tensor([1., 0., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.6453],\n",
      "        [0.3893],\n",
      "        [0.4621],\n",
      "        [0.5651]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5685, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5684512853622437\n",
      "tensor([0., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.4318],\n",
      "        [0.5230],\n",
      "        [0.5794],\n",
      "        [0.5466]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6709, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6708898544311523\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.4199],\n",
      "        [0.3885],\n",
      "        [0.6027],\n",
      "        [0.6329]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6943, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6942897439002991\n",
      "tensor([0., 0., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.6252],\n",
      "        [0.4141],\n",
      "        [0.4633],\n",
      "        [0.5339]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6915, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6914758086204529\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.6847],\n",
      "        [0.2715],\n",
      "        [0.3420],\n",
      "        [0.6862]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7622, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.762150764465332\n",
      "tensor([0., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.2924],\n",
      "        [0.5740],\n",
      "        [0.6549],\n",
      "        [0.4616]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6845, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.684533417224884\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.6158],\n",
      "        [0.4366],\n",
      "        [0.6169],\n",
      "        [0.2908]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7579, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.7579188346862793\n",
      "tensor([1., 0., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.6880],\n",
      "        [0.2723],\n",
      "        [0.3708],\n",
      "        [0.6178]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.4092, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.40919026732444763\n",
      "tensor([0., 1., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.4941],\n",
      "        [0.4930],\n",
      "        [0.4190],\n",
      "        [0.5097]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6611, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6611231565475464\n",
      "tensor([1., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.6907],\n",
      "        [0.5772],\n",
      "        [0.1399],\n",
      "        [0.5804]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.4036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.4036184251308441\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.5067],\n",
      "        [0.4522],\n",
      "        [0.2248],\n",
      "        [0.7130]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7028, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.7028396725654602\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.4566],\n",
      "        [0.3995],\n",
      "        [0.6265],\n",
      "        [0.3964]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6524, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.652373731136322\n",
      "tensor([1., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.3928],\n",
      "        [0.7800],\n",
      "        [0.1644],\n",
      "        [0.5346]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.4972, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.4971754550933838\n",
      "tensor([0., 0., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.3329],\n",
      "        [0.2273],\n",
      "        [0.9022],\n",
      "        [0.2904]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.2771, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.2771264910697937\n",
      "tensor([0., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.4288],\n",
      "        [0.5775],\n",
      "        [0.3192],\n",
      "        [0.4948]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7386, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.738628625869751\n",
      "tensor([1., 1., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.7947],\n",
      "        [0.7987],\n",
      "        [0.1211],\n",
      "        [0.1775]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1948, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.1947919726371765\n",
      "tensor([0., 0., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.2828],\n",
      "        [0.2909],\n",
      "        [0.4953],\n",
      "        [0.7386]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.4157, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.4157050848007202\n",
      "tensor([1., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.3966],\n",
      "        [0.3257],\n",
      "        [0.6885],\n",
      "        [0.4075]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(1.0277, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "1.0276912450790405\n",
      "[1,    61] loss: 0.051\n",
      "tensor([0., 0., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.3807],\n",
      "        [0.2023],\n",
      "        [0.8652],\n",
      "        [0.3205]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.4969, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.4969319999217987\n",
      "tensor([0., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.3848],\n",
      "        [0.5456],\n",
      "        [0.5667],\n",
      "        [0.3106]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5079, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5078760981559753\n",
      "tensor([1., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.2818],\n",
      "        [0.2320],\n",
      "        [0.4167],\n",
      "        [0.8159]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.9405, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.9404603242874146\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.7915],\n",
      "        [0.2195],\n",
      "        [0.6695],\n",
      "        [0.1630]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.9913, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.991331160068512\n",
      "tensor([1., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.4053],\n",
      "        [0.5813],\n",
      "        [0.1621],\n",
      "        [0.6757]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5036, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5035871267318726\n",
      "tensor([1., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.5602],\n",
      "        [0.1579],\n",
      "        [0.7890],\n",
      "        [0.3142]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6712, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6711633205413818\n",
      "tensor([0., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.1949],\n",
      "        [0.6583],\n",
      "        [0.3535],\n",
      "        [0.6463]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5278, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.5277931690216064\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.4279],\n",
      "        [0.2014],\n",
      "        [0.6142],\n",
      "        [0.6153]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8561, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8561238646507263\n",
      "tensor([1., 0., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.8365],\n",
      "        [0.1230],\n",
      "        [0.8693],\n",
      "        [0.0910]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7118, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.711801290512085\n",
      "tensor([0., 1., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.3915],\n",
      "        [0.6059],\n",
      "        [0.1902],\n",
      "        [0.6961]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.3928, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.39277908205986023\n",
      "tensor([0., 0., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.3512],\n",
      "        [0.8819],\n",
      "        [0.3889],\n",
      "        [0.1687]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.811439037322998\n",
      "tensor([1., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.7425],\n",
      "        [0.5611],\n",
      "        [0.2912],\n",
      "        [0.3373]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6301, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6301480531692505\n",
      "tensor([0., 0., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.0938],\n",
      "        [0.4025],\n",
      "        [0.9314],\n",
      "        [0.4065]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.3016, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.30160653591156006\n",
      "tensor([0., 1., 0., 0.], dtype=torch.float64)\n",
      "tensor([[0.1783],\n",
      "        [0.4787],\n",
      "        [0.8004],\n",
      "        [0.4859]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8025, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8025416731834412\n",
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.3498],\n",
      "        [0.4829],\n",
      "        [0.7498],\n",
      "        [0.3483]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7803, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.780260443687439\n",
      "tensor([1., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.2249],\n",
      "        [0.8342],\n",
      "        [0.3873],\n",
      "        [0.4624]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8106, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8106085658073425\n",
      "tensor([1., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.4367],\n",
      "        [0.8366],\n",
      "        [0.4402],\n",
      "        [0.2146]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.5173, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.517280638217926\n",
      "tensor([1., 0., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.6032],\n",
      "        [0.8167],\n",
      "        [0.1700],\n",
      "        [0.4079]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.8214, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.8213599324226379\n",
      "tensor([0., 0., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.1733],\n",
      "        [0.2189],\n",
      "        [0.7225],\n",
      "        [0.8516]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.2308, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.2307891547679901\n",
      "tensor([1., 0., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.4075],\n",
      "        [0.5974],\n",
      "        [0.3111],\n",
      "        [0.7109]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6304, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6303560137748718\n",
      "[1,    81] loss: 0.032\n",
      "tensor([0., 0., 0., 1.], dtype=torch.float64)\n",
      "tensor([[0.3711],\n",
      "        [0.2719],\n",
      "        [0.2883],\n",
      "        [0.9301]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.2984, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.2983996868133545\n",
      "tensor([1., 0., 1., 1.], dtype=torch.float64)\n",
      "tensor([[0.6181],\n",
      "        [0.4857],\n",
      "        [0.4444],\n",
      "        [0.5543]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6368, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.6367897987365723\n",
      "tensor([1., 0., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.7108],\n",
      "        [0.7107],\n",
      "        [0.1212],\n",
      "        [0.6178]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(1.1634, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "1.163381576538086\n",
      "tensor([1., 1., 1., 0.], dtype=torch.float64)\n",
      "tensor([[0.3074],\n",
      "        [0.8587],\n",
      "        [0.4558],\n",
      "        [0.3919]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.6537, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "running\n",
      "0.653725266456604\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34516\\1792241944.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m }\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# train(1, 'cnn')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain_cpu_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'densenet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34516\\3181110949.py\u001b[0m in \u001b[0;36mtrain_cpu_test\u001b[1;34m(num_epochs, model_type)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mrunning_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;31m# get the inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\s4469251\\Documents\\codes\\AKOA_TKR\\tkr_generator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnon_tkr_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NO_TKR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;31m# 50% chance left right flip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pt\\lib\\site-packages\\nibabel\\dataobj_images.py\u001b[0m in \u001b[0;36mget_fdata\u001b[1;34m(self, caching, dtype)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;31m# For array proxies, will attempt to confine data array to dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;31m# during scaling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcaching\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'fill'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fdata_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pt\\lib\\site-packages\\nibabel\\arrayproxy.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    368\u001b[0m             \u001b[0mScaled\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \"\"\"\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_scaled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslicer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pt\\lib\\site-packages\\nibabel\\arrayproxy.py\u001b[0m in \u001b[0;36m_get_scaled\u001b[1;34m(self, dtype, slicer)\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[0mscl_inter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscl_inter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;31m# Read array and upcast as necessary for big slopes, intercepts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mscaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_read_scaling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_unscaled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslicer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslicer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscl_slope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscl_inter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mscaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpromote_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pt\\lib\\site-packages\\nibabel\\arrayproxy.py\u001b[0m in \u001b[0;36m_get_unscaled\u001b[1;34m(self, slicer)\u001b[0m\n\u001b[0;32m    314\u001b[0m                                        \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                                        mmap=self._mmap)\n\u001b[0m\u001b[0;32m    317\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_fileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m             return fileslice(fileobj,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pt\\lib\\site-packages\\nibabel\\volumeutils.py\u001b[0m in \u001b[0;36marray_from_file\u001b[1;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'readinto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mdata_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[0mn_read\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m         \u001b[0mneeds_copy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pt\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pt\\lib\\_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pt\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[1;31m# Read a chunk of data from the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m             \u001b[0muncompress\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pt\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[0mread\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Param = {\n",
    "    'LR': 0.0001,\n",
    "    'WC': 0.0001,\n",
    "    'PL': 1\n",
    "}\n",
    "# train(1, 'cnn')\n",
    "train_cpu_test(1, 'densenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "\n",
    "def train_cpu(num_epochs, model_type):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    if model_type == 'resnet34':\n",
    "        model = models.resnet34(pretrained=False)\n",
    "                # Download torchvision pretrained model from: https://download.pytorch.org/models/resnet34-333f7ec4.pth\n",
    "        model.load_state_dict(torch.load('resnet34-333f7ec4.pth'))\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1, bias=True)\n",
    "        model.to(device)\n",
    "    elif model_type == 'densenet':\n",
    "        model = models.densenet201(pretrained=False)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, 1, bias=True)\n",
    "    # Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
    "    \n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=Param['LR'], weight_decay=Param['WC'])\n",
    "    best_accuracy = 0.0\n",
    "    train_loader = TKRDataset('R:\\OAIKNEE-Q1126\\OAI_UQ_processed\\AKOA_TKR_Data', 1)\n",
    "    \n",
    "\n",
    "    # Define your execution device\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "            # get the inputs\n",
    "            images = np.stack((images,)*3, axis=1)\n",
    "            images = torch.tensor(images, dtype=float).to(device, dtype=float)\n",
    "            labels = torch.tensor(labels, dtype=float).to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # predict classes using images from the training set\n",
    "            outputs = model(images.float())\n",
    "            pred = torch.sigmoid(outputs)\n",
    "            \n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_fn(pred[:,0], labels.float())\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            if i % 20 == 0:    \n",
    "                # print every 1000 (twice per epoch) \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 20))\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "    torch.save(model.state_dict(), 'best_weights.pth')\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_training_accuracy():\n",
    "    train_loader = TKRDataset('R:\\OAIKNEE-Q1126\\OAI_UQ_processed\\AKOA_TKR_Data', 1)\n",
    "    model = models.densenet201(pretrained=False)\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, 1, bias=True)\n",
    "    model.load_state_dict('weights.pth')\n",
    "    for i, (images, labels) in enumerate(train_loader, 0):\n",
    "        images = np.stack((images,)*3, axis=1)\n",
    "        images = torch.tensor(images, dtype=float)\n",
    "        labels = torch.tensor(labels, dtype=float)\n",
    "        # predict classes using images from the training set\n",
    "        outputs = model(images.float())\n",
    "        pred = torch.sigmoid(outputs)\n",
    "        for element in pred:\n",
    "            if element > 0.5:\n",
    "                element = 1\n",
    "            else:\n",
    "                element = 0\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = TKRDataset('R:\\OAIKNEE-Q1126\\OAI_UQ_processed\\AKOA_TKR_Data', 0)\n",
    "a,b = train_loader.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 256, 256)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = train_loader.__getitem__(0)\n",
    "images = np.stack((a,)*3, axis=1)\n",
    "images = torch.tensor(images, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(b, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet201(pretrained=False)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 1, bias=True)\n",
    "outputs = model(images.float())\n",
    "pred = torch.sigmoid(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "labels = torch.tensor(np.stack(b, axis=0), dtype=float)\n",
    "loss = loss_fn(pred[:,0], labels.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6687, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[149.,  77.,   6., ...,   0.,   0.,   0.],\n",
       "         [101.,  52.,  22., ...,   0.,   0.,   0.],\n",
       "         [ 72.,  65.,  37., ...,   1.,   0.,   0.],\n",
       "         ...,\n",
       "         [ 87.,  39.,  28., ...,   0.,   0.,   0.],\n",
       "         [149.,  20.,  23., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.]]),\n",
       "  array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "  <a list of 256 BarContainer objects>),\n",
       " (array([[256.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [102.,  78.,  25., ...,   0.,   0.,   0.],\n",
       "         [ 19., 103.,  31., ...,   0.,   0.,   1.],\n",
       "         ...,\n",
       "         [152.,  92.,  11., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.]]),\n",
       "  array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "  <a list of 256 BarContainer objects>),\n",
       " (array([[165.,  45.,   4., ...,   0.,   0.,   0.],\n",
       "         [135.,  47.,   5., ...,   0.,   0.,   0.],\n",
       "         [134.,  36.,  17., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [ 95.,  19.,  18., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.]]),\n",
       "  array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "  <a list of 256 BarContainer objects>),\n",
       " (array([[256.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [226.,  21.,   6., ...,   0.,   0.,   0.],\n",
       "         [137.,  59.,  18., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [253.,   3.,   0., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.]]),\n",
       "  array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "  <a list of 256 BarContainer objects>),\n",
       " (array([[145.,  71.,   4., ...,   0.,   0.,   0.],\n",
       "         [ 99.,  59.,   9., ...,   0.,   0.,   0.],\n",
       "         [ 83.,  59.,  21., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [ 70., 113.,  18., ...,   0.,   0.,   0.],\n",
       "         [162.,  41.,  11., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.]]),\n",
       "  array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "  <a list of 256 BarContainer objects>),\n",
       " (array([[256.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [210.,   2.,   9., ...,   0.,   0.,   0.],\n",
       "         [ 89.,  19.,  19., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [242.,  14.,   0., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.]]),\n",
       "  array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "  <a list of 256 BarContainer objects>),\n",
       " (array([[141.,  91.,  12., ...,   0.,   0.,   0.],\n",
       "         [ 77.,  86.,  14., ...,   0.,   0.,   0.],\n",
       "         [ 69.,  85.,  11., ...,   1.,   0.,   0.],\n",
       "         ...,\n",
       "         [ 55., 119.,  27., ...,   1.,   0.,   0.],\n",
       "         [189.,  53.,  11., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.]]),\n",
       "  array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "  <a list of 256 BarContainer objects>),\n",
       " (array([[254.,   2.,   0., ...,   0.,   0.,   0.],\n",
       "         [175.,  31.,  32., ...,   0.,   0.,   0.],\n",
       "         [145.,  42.,   7., ...,   0.,   0.,   0.],\n",
       "         ...,\n",
       "         [250.,   6.,   0., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "         [256.,   0.,   0., ...,   0.,   0.,   0.]]),\n",
       "  array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       "  <a list of 256 BarContainer objects>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "[plt.hist(a[i]) for i in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 256, 256)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(a, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.    ,   0.    , 212.625 , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    , 300.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    , 149.1875, ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        ...,\n",
       "        [  0.    ,   0.    , 165.9375, ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    , 146.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,  31.0625, ...,   0.    ,   0.    ,\n",
       "           0.    ]],\n",
       "\n",
       "       [[  0.    ,   0.    ,  34.6875, ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    , 143.0625, ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    , 159.75  , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        ...,\n",
       "        [  0.    ,   0.    ,  41.25  , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,  36.625 , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   9.625 , ...,   0.    ,   0.    ,\n",
       "           0.    ]],\n",
       "\n",
       "       [[  0.    ,   0.    , 300.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    , 300.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    , 143.875 , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        ...,\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        ...,\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ]],\n",
       "\n",
       "       [[  0.    ,   0.    ,  29.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,  42.5   , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,  39.9375, ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        ...,\n",
       "        [  0.    ,   0.    ,  12.25  , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,  16.5   , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   2.25  , ...,   0.    ,   0.    ,\n",
       "           0.    ]],\n",
       "\n",
       "       [[  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        ...,\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ],\n",
       "        [  0.    ,   0.    ,   0.    , ...,   0.    ,   0.    ,\n",
       "           0.    ]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.clip(a, 0, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cpu device\n"
     ]
    }
   ],
   "source": [
    "Param = {\n",
    "    'LR': 0.00001,\n",
    "    'WC': 0.0001\n",
    "}\n",
    "train_cpu(0, 'densenet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69180c7bf0979f4b53bf3b33d4883f1e1fccb00fc3a066935c25f662143ffe9a"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 ('bpr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
